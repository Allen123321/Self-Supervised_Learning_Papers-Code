# Self-Supervised learning (SSL)

![Relationship](https://github.com/Allen123321/self-supervised_learning/blob/main/image.png)

## Papers
### Papers 2021
+ Self-Supervised Representation Learning for RGB-D Salient Object Detection([Paper](https://arxiv.org/pdf/2101.12482.pdf)) <br>
+ Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis ([Paper](https://arxiv.org/abs/2102.04830)) ([Code](https://github.com/thuiar/Self-MM))<br>
+ Understanding self-supervised Learning Dynamics without Contrastive Pairs ([Paper](https://arxiv.org/pdf/2102.06810.pdf)) ([Code](https://github.com/facebookresearch/luckmatters/tree/master/ssl))<br>
+ Self-supervised Learning from a Multi-view Perspective.([Paper](https://arxiv.org/abs/2006.05576))(**ICLR 2021**)
+ Contrast to Divide: self-supervised pre-training for learning with noisy labels.([Paper](https://openreview.net/pdf?id=uB5x7Y2qsFR))(**ICLR 2021**)(**[Code](https://github.com/ContrastToDivide/C2D)**)
+ Self-Supervised Variational Auto-Encoders.([Paper](https://arxiv.org/abs/2010.02014))(**ICLR 2021**)
+ Dense Contrastive Learning for Self-Supervised Visual Pre-Training.([Paper](https://arxiv.org/abs/2011.09157))(**CVPR 2021**)(**[Code](https://github.com/CoinCheung/denseCL)**)([blog](https://blog.csdn.net/Jesse_08/article/details/111089264)) <br>
+ There is More than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking with Sound by Distilling Multimodal Knowledge.([Paper](https://arxiv.org/abs/2103.01353))(**CVPR 2021**)
+ AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations from Self-Trained Negative Adversaries.([Paper](https://arxiv.org/abs/2011.08435))(**CVPR 2021**)(**[Code](https://github.com/maple-research-lab/AdCo)**)
+ Exploring Simple Siamese Representation Learning.([Paper](https://arxiv.org/abs/2011.10566))
+ Barlow Twins: Self-Supervised Learning via Redundancy Reduction.([Paper](https://arxiv.org/abs/2103.03230))
+ Spatially Consistent Representation Learning.([Paper](https://arxiv.org/abs/2103.06122))(**CVPR 2021**)
+ Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning.([Paper](https://arxiv.org/abs/2009.05769))(**CVPR 2021**)
+ Efficient Visual Pretraining with Contrastive Detection. ([Paper](https://arxiv.org/pdf/2103.10957.pdf))
+ Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning.([Paper](https://arxiv.org/abs/2011.10043))
+ An Empirical Study of Training Self-Supervised Visual Transformers.([Paper](https://arxiv.org/abs/2104.02057))(**MOCO v3**)
+ SiT: Self-supervised vIsion Transformer.([Paper](https://arxiv.org/abs/2104.03602))(Transformer)
### NeurIPS 2020
+ Self-Supervised Relational Reasoning for Representation Learning.([Paper.2020](https://arxiv.org/pdf/2006.05849.pdf))(**[Code](https://github.com/mpatacchiola/self-supervised-relational-reasoning)**) <br>
1.Unsupervised Representation Learning by InvariancePropagation.([Paper](https://arxiv.org/abs/2010.11694)) <br>
2.Hard Negative Mixing for Contrastive Learning.([Paper](https://arxiv.org/abs/2010.01028)) <br>
3.Debiased Contrastive Learning.([Paper](https://arxiv.org/abs/2007.00224)) <br>
4.CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances.([Paper](https://arxiv.org/abs/2007.08176)) <br>
### recently
1.Self-supervised visual feature learning with deep neural networks: A survey.([paper.2019](https://arxiv.org/pdf/1902.06162.pdf)) <br>
2.A Survey on Semi-, Self- and Unsupervised Learning for Image Classification([paper.2020](https://arxiv.org/pdf/2002.08721.pdf))<br>
3.Self-supervised Learning: Generative or Contrastive.([paper.2020](https://arxiv.org/pdf/2006.08218.pdf)) <br>
4.A Framework For Contrastive Self-Supervised Learning And Designing A New Approach.([Paper.2020](https://arxiv.org/pdf/2009.00104.pdf)) <br>
5.**Momentum Contrast for Unsupervised Visual Representation Learning.**([paper.2019](https://arxiv.org/pdf/1911.05722.pdf)).([code](https://github.com/facebookresearch/moco)) (**MOCO  State-of-The-Art**)<br>
5.1**Improved Baselines with Momentum Contrastive Learning**([paper.2020](https://arxiv.org/abs/2003.04297)). (**MOCO V2**)<br>
6.Revisiting Self-Supervised Visual Representation Learning.([paper.2019](https://arxiv.org/pdf/1901.09005.pdf)) <br>
7.Self-supervised Label Augmentation via Input Transformations.([paper.2019](https://arxiv.org/pdf/1910.05872.pdf)) <br>
8.**A Simple Framework for Contrastive Learning of Visual Representations.** ([Paper.2020](https://arxiv.org/abs/2002.05709))(**[SimCLR](https://github.com/google-research/simclr)**)(**State-of-The-Art.**) <br>
9.Boosting few-shot visual learning with self-supervision.([Paper.2019](https://openaccess.thecvf.com/content_ICCV_2019/papers/Gidaris_Boosting_Few-Shot_Visual_Learning_With_Self-Supervision_ICCV_2019_paper.pdf))(ICCV 2019) <br>
10.**Bootstrap your own latent: A new approach to self-supervised Learning**([Paper.2020](https://arxiv.org/abs/2006.07733))(**BYOL**) <br>
11.**Unsupervised Learning of Visual Features by Contrasting Cluster Assignments**([Paper.2020](https://arxiv.org/abs/2006.09882))(**Swav**)([Code](https://github.com/facebookresearch/swav)) <br>
12.Self-Supervised Learning for Large-Scale Unsupervised Image Clustering.([Paper.2020](https://arxiv.org/abs/2006.09882))<br>
13.Big Self-Supervised Models are Strong Semi-Supervised Learners.([Paper.2020](https://arxiv.org/abs/2006.10029))<br>
14.Self-Supervised Learning of Pretext-Invariant Representations.([Paper.2019](https://arxiv.org/abs/1912.01991))<br>
15.ClusterFit: Improving Generalization of Visual Representations.([Paper.2019](https://arxiv.org/abs/1912.03330))<br>
16.Self-Supervised Domain Adaptation with Consistency Training.([Paper.2020](https://arxiv.org/abs/2010.07539))<br>
17.Scaling and Benchmarking Self-Supervised Visual Representation Learning.([Paper.2019](https://arxiv.org/abs/1905.01235))<br>
18.Self-Supervised Learning of Pretext-Invariant Representations.([Paper.2020](https://arxiv.org/abs/1912.01991))<br>

### Contrastive Self-supervised Learning
+ Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere ([Paper.2020](https://arxiv.org/abs/2005.10242)) **(ICML)**<br>
+ What Makes for Good Views for Contrastive Learning?([Paper.2020](https://arxiv.org/pdf/2005.10243.pdf))<br>
1.A Framework For Contrastive Self-Supervised Learning And Designing A New Approach.([Paper.2020](https://arxiv.org/pdf/2009.00104.pdf))(Author:William Falcon) <br>
2.Representation Learning with Contrastive Predictive Coding.([Paper.2018](https://arxiv.org/pdf/1807.03748.pdf).) (DeepMind)<br>
3.Data-Efficient Image Recognition with Contrastive Predictive.([Paper.2019](https://arxiv.org/pdf/1905.09272.pdf)) (**CPC**) <br>
4.Contrastive Multiview Coding.([Paper.2019](https://arxiv.org/abs/1906.05849))<br>
5.Learning deep representations by mutual information estimation and maximization.([Paper.2018](https://arxiv.org/abs/1808.06670)) (**AMDIM**)(ICLR 2019)<br>
6.**Comparing to Learn: Surpassing ImageNet Pretraining on Radiographs By Comparing Image Representations**([Paper.2020](https://arxiv.org/abs/2007.07423)) ([Code(C2L_MICCAI2020)](https://github.com/funnyzhou/C2L_MICCAI2020)<br>

### Before SSL Revolution：Pretext Task(Rotation,Jigsaw Puzzle,Colorization)
1.Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles.([paper.2016](https://arxiv.org/pdf/1603.09246.pdf)) <br>
2.Unsupervised Representation Learning by Predicting Image Rotations.([paper.2018](https://arxiv.org/pdf/1803.07728.pdf)).([code](https://github.com/gidariss/FeatureLearningRotNet)) <br>
3.Context Encoders: Feature Learning by Inpainting.([paper.2016](https://arxiv.org/abs/1604.07379)) <br>
4.Deep Clustering for Unsupervised Learning of Visual Features.([paper.2018](https://arxiv.org/abs/1807.05520)) <br>
5.Shuffle and Learn: Unsupervised Learning using Temporal Order Verification.([paper.2016](https://arxiv.org/abs/1603.08561)) <br>
6.Learning Features by Watching Objects Move.([paper.2016](https://arxiv.org/abs/1612.06370)) <br>
7.Colorization as a proxy task for visual understanding.([paper.2017](https://arxiv.org/abs/1703.04044)) <br>
### Related papers
1.Understanding Self-supervised Learning with Dual Deep Networks.([paper.2020](https://arxiv.org/pdf/2010.00578.pdf))(**[Code](https://github.com/facebookresearch/luckmatters/tree/master/ssl)**) <br>
2.Cross Pixel Optical Flow Similarity for Self-Supervised Learning.([paper.2018](https://arxiv.org/pdf/1807.05636.pdf)) <br>
3.Cross and Learn: Cross-Modal Self-Supervision.([paper.2018](https://arxiv.org/abs/1811.03879)) <br>
4.Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization.([paper.2018](https://arxiv.org/abs/1807.00230)) <br>
5.Audio-Visual Scene Analysis with Self-Supervised Multisensory Features.([paper.2018](https://openaccess.thecvf.com/content_ECCV_2018/papers/Andrew_Owens_Audio-Visual_Scene_Analysis_ECCV_2018_paper.pdf)) <br>
6.Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles.([paper.2018](https://arxiv.org/abs/1811.09795)) <br>
7.Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.([paper.2018](https://arxiv.org/pdf/1811.11387.pdf)) <br>
8.Self-Supervised Video Representation Learning With Odd-One-Out Networks.([paper.2017](https://arxiv.org/abs/1611.06646)) <br>
9.Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic Imagery.([paper.2017](https://arxiv.org/abs/1711.09082)) <br>
10.Transitive invariance for self-supervised visual representation learning.([paper.2017](https://arxiv.org/abs/1708.02901)) <br>
11.Improvements to context-based self-supervised learning.([paper.2017](https://arxiv.org/abs/1711.06379)) <br>
12.Boosting Self-Supervised Learning via Knowledge Transfer.([paper.2018](https://arxiv.org/abs/1805.00385)) <br>
13.Improving Spatiotemporal Self-Supervision by Deep Reinforcement Learning.([paper.2018](https://arxiv.org/abs/1807.11293)) <br>
14.Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks.([paper.2014](https://arxiv.org/abs/1406.6909)) <br>
15.Self-supervised Co-training for Video Representation Learning.([Paper.2020](https://arxiv.org/pdf/2010.09709.pdf)) <br>
16.CURL: Contrastive Unsupervised Representations for Reinforcement Learning.([Paper.2020](https://arxiv.org/abs/2004.04136)) <br>

### Unsupervised Learning

1.Unsupervised Representation Learning by Predicting Image Rotations.([paper.2018](https://arxiv.org/abs/1803.07728)) <br>
2.Unsupervised Feature Learning via Non-Parametric Instance-level Discrimination.**(Memory Bank)**([paper.2018](https://arxiv.org/abs/1805.01978)) <br>
3.Unsupervised Visual Representation Learning by Context Prediction.([paper.2015](https://arxiv.org/abs/1505.05192)) <br>
4.SCAN: Learning to Classify Images without Labels([Paper 2020 ECCV](https://arxiv.org/pdf/2005.12320.pdf))**([code](https://github.com/wvangansbeke/Unsupervised-Classification))** <br>

#### Self-Supervised Learning & Unsupervised Learning with GAN
1.Transformation GAN for Unsupervised Image Synthesis and Representation Learning.([Paper.CVPR2020](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Transformation_GAN_for_Unsupervised_Image_Synthesis_and_Representation_Learning_CVPR_2020_paper.pdf)) <br>
2.Self-Supervised Viewpoint Learning from Image Collections.([Paper.CVPR2020](https://arxiv.org/abs/2004.01793)) <br>
3.Self-supervised Domain-aware Generative Network for Generalized Zero-shot learning.([Paper.CVPR2020](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Self-Supervised_Domain-Aware_Generative_Network_for_Generalized_Zero-Shot_Learning_CVPR_2020_paper.pdf)) <br>
4.PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models.([Paper.CVPR2020](https://openaccess.thecvf.com/content_CVPR_2020/papers/Menon_PULSE_Self-Supervised_Photo_Upsampling_via_Latent_Space_Exploration_of_Generative_CVPR_2020_paper.pdf)) <br>
#### Multi-Modal
Multi-Modal Domain Adaptation for Fine-Grained Action Recognition.([Paper.CVPR2020](https://arxiv.org/abs/2001.09691)) <br>



### blog
[Self-Supervised Representation Learning](https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html)

## Codes-Example
+ PyTorch-BYOL(PyTorch implementation of Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning.)([code_1](https://github.com/sthalles/PyTorch-BYOL)).([code_2](https://github.com/lucidrains/byol-pytorch))
+ BYOL-tensorflow2 on CIFAR-10 dataset.([Code](https://github.com/garder14/byol-tensorflow2))
+ SimCLR-TensorFlow2 on CIFAR-10 dataset.([Code](https://github.com/garder14/simclr-tensorflow2))
+ PyTorch-DIM(self-supervised learning with Deep InfoMax)([Code](https://github.com/ZhaoyangLi-nju/Self-supervised-DIM_stl10))
+ MOCO -> CIFAR demo on Colab GPU.([MOCO](https://colab.research.google.com/github/facebookresearch/moco/blob/colab-notebook/colab/moco_cifar10_demo.ipynb))
### Dataset
+ [STL10](https://cs.stanford.edu/~acoates/stl10/)
+ [CIFAR-10]

### Related blog -> Vision Transformer

[Vision Transformer 超详细解读 (原理分析+代码解读) (一)](https://zhuanlan.zhihu.com/p/340149804)


